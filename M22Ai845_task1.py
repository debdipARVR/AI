# -*- coding: utf-8 -*-
"""M22AI845_Task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gh6WriW9uZa0tpjCWZKPRrp7gBdgeZpw
"""

import torch
from torch import nn
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torchvision.datasets import VOCDetection
from torchvision.transforms import ToTensor
from torchvision.transforms import Resize, Normalize
from torch.utils.data import random_split
import matplotlib.pyplot as plt

print(torch.__version__)

#q2 - a,b ; a

# Define the desired image size
target_size = (256, 256)

# Defining the mean and SD. Taking common numbers accepted in computer vision family.
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

# Defining the transformation ie first resizing ,normalising and then transforming
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

Train_transform = transforms.Compose(
                      [Resize(target_size),
                       ToTensor(),
                       normalize])



train_data = torchvision.datasets.VOCDetection (root='data',
                                   year = "2007",
                                   image_set="train",
                                   download=True,
                                   transform=Train_transform)



# Spliting the data sets into the
train_data_set_1 = round(len(train_data)*(0.8))
val_data_1 = round(len(train_data)*(0.1))
test_data_1 = round(len(train_data)*(0.1))
train_set_1, val_set_1, test_set_1 = random_split(train_data, [train_data_set_1,val_data_1,test_data_1])

# Spliting the data sets into the
train_data_set_2 = round(len(train_data)*(0.7))
val_data_2 = round(len(train_data)*(0.1))
test_data_2 = round(len(train_data)*(0.2))
train_set_2, val_set_2, test_set_2 = random_split(train_data, [train_data_set_2,val_data_2,test_data_2])






print("Train set size:", len(train_set_1))
print("Validation set size:", len(val_set_1))
print("Test set size:", len(test_set_1))

print("Train set size:", len(train_set_2))
print("Validation set size:", len(val_set_2))
print("Test set size:", len(test_set_2))

import torch
from torch import nn
import torchvision
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms , datasets
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

#my system was unable to train pascal voc dataset , I went ahead and performed my optimisation on MNIST dataset.
# copying the dataset and adding the noice.
#Reference for gause function creation : https://discuss.pytorch.org/t/how-to-add-noise-to-mnist-dataset-when-using-pytorch/59745
class AddGaussianNoise(object):
    def __init__(self, mean=0., std=1.):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)



transform1=transforms.Compose([
    transforms.ToTensor(),
    AddGaussianNoise(0., 1.),
    transforms.Normalize((0.5), (0.5)),

])


transform2 = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5))
    ])
mnist_data_test = datasets.MNIST(root ='data',train=True, download=True,transform=transform1)
mnist_data_train = datasets.MNIST(root ='data',train=True, download=True,transform=transform2)
data_loader_test = torch.utils.data.DataLoader(dataset=mnist_data_test,
                                          batch_size=64,
                                          shuffle=False)
mnist_data_train = torch.utils.data.DataLoader(dataset=mnist_data_train,
                                          batch_size=64,
                                          shuffle=False)

dataiter = iter(data_loader_test)
images, labels = next(dataiter)
print(torch.min(images), torch.max(images))

#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256,128),
        nn.ReLU(),
        nn.Linear(128,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,128),
        nn.ReLU(),
        nn.Linear(128,256),
        nn.ReLU(),
        nn.Linear(256,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)

# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 128),
        nn.ReLU(),
        nn.Linear(128,64),
        nn.ReLU(),
        nn.Linear(64,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,64),
        nn.ReLU(),
        nn.Linear(64,128),
        nn.ReLU(),
        nn.Linear(128,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 64),
        nn.ReLU(),
        nn.Linear(64,12),
        nn.ReLU(),
        nn.Linear(12,6),
        nn.ReLU(),
        nn.Linear(6,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 6),
        nn.ReLU(),
        nn.Linear(6,12),
        nn.ReLU(),
        nn.Linear(12,64),
        nn.ReLU(),
        nn.Linear(64,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded



#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 32),
        nn.ReLU(),
        nn.Linear(32,16),
        nn.ReLU(),
        nn.Linear(16,8),
        nn.ReLU(),
        nn.Linear(8,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 8),
        nn.ReLU(),
        nn.Linear(8,16),
        nn.ReLU(),
        nn.Linear(16,32),
        nn.ReLU(),
        nn.Linear(32,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded



#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))



#Auto Encoder creation.

#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 16),
        nn.ReLU(),
        nn.Linear(16,12),
        nn.ReLU(),
        nn.Linear(12,8),
        nn.ReLU(),
        nn.Linear(8,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 8),
        nn.ReLU(),
        nn.Linear(8,12),
        nn.ReLU(),
        nn.Linear(12,16),
        nn.ReLU(),
        nn.Linear(16,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))

#Masking code refered from https://stackoverflow.com/questions/68929785/how-to-apply-mask-to-image-tensors-in-pytorch
class PixelMask(object):
    def __init__(self, mask_percentage):
        self.mask_percentage = mask_percentage

    def __call__(self, img):
        num_pixels = img.numel()
        num_pixels_to_mask = int(self.mask_percentage * num_pixels)
       #image to a 1D tensor
        flattened_img = img.view(-1)

        # Create a mask tensor with 0s for pixels to be masked
        mask = torch.zeros_like(flattened_img)

        # Set the first num_pixels_to_mask pixels in the mask tensor to 1
        mask[:num_pixels_to_mask] = 1

        # Apply the mask to the flattened image
        masked_img = flattened_img * mask

        # Reshape the masked image back to its original shape
        masked_img = masked_img.view(img.size())

        return masked_img

mask_percentage = 0.2
transform1 = transforms.Compose([
    transforms.ToTensor(),
    PixelMask(mask_percentage),
    transforms.Normalize((0.5), (0.5)),
])

transform2 = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5), (0.5)),
])



mnist_data_test = datasets.MNIST(root ='data',train=True, download=True,transform=transform2)
mnist_data_train = datasets.MNIST(root ='data',train=True, download=True,transform=transform1)
data_loader_test = torch.utils.data.DataLoader(dataset=mnist_data_test,
                                          batch_size=64,
                                          shuffle=False)
mnist_data_train = torch.utils.data.DataLoader(dataset=mnist_data_train,
                                          batch_size=64,
                                          shuffle=False)

#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256,128),
        nn.ReLU(),
        nn.Linear(128,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,128),
        nn.ReLU(),
        nn.Linear(128,256),
        nn.ReLU(),
        nn.Linear(256,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded



#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))

mask_percentage = 0.4
transform1 = transforms.Compose([
    transforms.ToTensor(),
    PixelMask(mask_percentage),
    transforms.Normalize((0.5), (0.5)),
])

transform2 = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5), (0.5)),
])



mnist_data_test = datasets.MNIST(root ='data',train=True, download=True,transform=transform2)
mnist_data_train = datasets.MNIST(root ='data',train=True, download=True,transform=transform1)
data_loader_test = torch.utils.data.DataLoader(dataset=mnist_data_test,
                                          batch_size=64,
                                          shuffle=False)
mnist_data_train = torch.utils.data.DataLoader(dataset=mnist_data_train,
                                          batch_size=64,
                                          shuffle=False)



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256,128),
        nn.ReLU(),
        nn.Linear(128,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,128),
        nn.ReLU(),
        nn.Linear(128,256),
        nn.ReLU(),
        nn.Linear(256,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded



#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))

mask_percentage = 0.6
transform1 = transforms.Compose([
    transforms.ToTensor(),
    PixelMask(mask_percentage),
    transforms.Normalize((0.5), (0.5)),
])

transform2 = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5), (0.5)),
])



mnist_data_test = datasets.MNIST(root ='data',train=True, download=True,transform=transform2)
mnist_data_train = datasets.MNIST(root ='data',train=True, download=True,transform=transform1)
data_loader_test = torch.utils.data.DataLoader(dataset=mnist_data_test,
                                          batch_size=64,
                                          shuffle=False)
mnist_data_train = torch.utils.data.DataLoader(dataset=mnist_data_train,
                                          batch_size=64,
                                          shuffle=False)



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256,128),
        nn.ReLU(),
        nn.Linear(128,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,128),
        nn.ReLU(),
        nn.Linear(128,256),
        nn.ReLU(),
        nn.Linear(256,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded



#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))

mask_percentage = 0.8
transform1 = transforms.Compose([
    transforms.ToTensor(),
    PixelMask(mask_percentage),
    transforms.Normalize((0.5), (0.5)),
])

transform2 = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5), (0.5)),
])



mnist_data_test = datasets.MNIST(root ='data',train=True, download=True,transform=transform2)
mnist_data_train = datasets.MNIST(root ='data',train=True, download=True,transform=transform1)
data_loader_test = torch.utils.data.DataLoader(dataset=mnist_data_test,
                                          batch_size=64,
                                          shuffle=False)
mnist_data_train = torch.utils.data.DataLoader(dataset=mnist_data_train,
                                          batch_size=64,
                                          shuffle=False)



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256,128),
        nn.ReLU(),
        nn.Linear(128,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,128),
        nn.ReLU(),
        nn.Linear(128,256),
        nn.ReLU(),
        nn.Linear(256,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded



#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)



# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, img1, recon))

import torch
from torch import nn
import torchvision
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms , datasets
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

#my system was unable to train pascal voc dataset , I went ahead and performed my optimisation on MNIST dataset.
# copying the dataset and adding the noice.
#Reference for gause function creation : https://discuss.pytorch.org/t/how-to-add-noise-to-mnist-dataset-when-using-pytorch/59745
class AddGaussianNoise(object):
    def __init__(self, mean=0., std=1.):
        self.std = std
        self.mean = mean

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)



transform1=transforms.Compose([
    transforms.ToTensor(),
    AddGaussianNoise(0., 1.),
    transforms.Normalize((0.5), (0.5)),

])


transform2 = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5))
    ])
mnist_data_test = datasets.MNIST(root ='data',train=True, download=True,transform=transform1)
mnist_data_train = datasets.MNIST(root ='data',train=True, download=True,transform=transform2)
data_loader_test = torch.utils.data.DataLoader(dataset=mnist_data_test,
                                          batch_size=64,
                                          shuffle=False)
mnist_data_train = torch.utils.data.DataLoader(dataset=mnist_data_train,
                                          batch_size=64,
                                          shuffle=False)



#Auto Encoder creation.
#Tutorial lectures.

class Autoencoder(nn.Module):
  def __init__(self):
    super(Autoencoder,self).__init__()
    self.encoder = nn.Sequential(
        nn.Linear(784, 256),
        nn.ReLU(),
        nn.Linear(256,128),
        nn.ReLU(),
        nn.Linear(128,12),
        nn.ReLU(),
        nn.Linear(12,3),
                   )

    self.decoder = nn.Sequential(
        nn.Linear(3, 12),
        nn.ReLU(),
        nn.Linear(12,128),
        nn.ReLU(),
        nn.Linear(128,256),
        nn.ReLU(),
        nn.Linear(256,784),
        nn.Tanh()
        )


  def forward(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded


#initializing the adam optimiser
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)






# Traning loop
num_epochs = 15
outputs = []
for epoch in range(num_epochs):
    for (img1, _), (img2, _) in zip(data_loader_test, mnist_data_train):
        #print(img1.shape)
        #print(img2.shape)
        img1 = img1.reshape(-1, 28*28)
        img2 = img2.reshape(-1, 28*28)
        #print(img1.shape)
        #print(img2.shape)
        recon = model(img1)
        #print(recon.shape)
        loss = criterion(recon, img2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


transform = transforms.ToTensor()
test_dataset_MNIST = torchvision.datasets.FashionMNIST(root='data', train=False, transform=transform, download=True)
test_loader_MNIST = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)

#reference https://discuss.pytorch.org/t/load-only-a-part-of-the-network-with-pretrained-weights/88397/2

